# from pathlib import Path
# import logging
# import typer
# import pandas as pd
# from sklearn.datasets import fetch_openml

# from boston_housing import dataset
# from boston_housing.config import PROCESSED_DATA_DIR, RAW_DATA_DIR
# from boston_housing.modeling import train as train_module

# # Inicializa Typer e Logger
# app = typer.Typer()
# logger = logging.getLogger(__name__)
# logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")


# @app.command()
# def main(
#     raw_filename: Path = RAW_DATA_DIR / "boston_raw.csv",
#     processed_filename: Path = PROCESSED_DATA_DIR / "boston.csv",
#     model_type: str = "random_forest",
# ):
#     """
#     Pipeline Boston Housing:
#     1Ô∏è‚É£ Carrega dataset Boston Housing (OpenML) e salva raw/processado
#     2Ô∏è‚É£ Separa features e target
#     3Ô∏è‚É£ Treina modelo de regress√£o e loga no MLFlow
#     """
#     # --- 1Ô∏è‚É£ Carregar dataset ---
#     logger.info("üì• Carregando Boston Housing dataset...")
#     boston = fetch_openml(name="boston", version=1, as_frame=True)
#     df = boston.frame  # j√° vem como DataFrame

#     # Salvar raw e processed
#     dataset.save_raw(df, raw_filename.name)
#     processed_path = dataset.save_processed(df, processed_filename.name)
#     logger.info(f"‚úÖ Dataset processado salvo em: {processed_path}")

#     # --- 2Ô∏è‚É£ Separar features e target ---
#     logger.info("üîß Separando features e target...")
#     df_processed = pd.read_csv(processed_path)
#     if "target" not in df_processed.columns:
#         raise ValueError("Coluna 'target' n√£o encontrada no dataset processado.")
    
#     features_path = PROCESSED_DATA_DIR / "features.csv"
#     labels_path = PROCESSED_DATA_DIR / "labels.csv"

#     df_processed.drop(columns=["target"]).to_csv(features_path, index=False)
#     df_processed["target"].to_csv(labels_path, index=False)
#     logger.info(f"‚úÖ Features salvas em: {features_path}")
#     logger.info(f"‚úÖ Labels salvas em: {labels_path}")

#     # --- 3Ô∏è‚É£ Treinar modelo ---
#     logger.info(f"üèãÔ∏è Treinando modelo de regress√£o: {model_type}")
#     train_module.main(
#         features_path=features_path,
#         labels_path=labels_path,
#         overwrite=True,
#         experiment_name="boston_housing_experiment",
#         model_type=model_type,
#     )

#     logger.info("‚úÖ Pipeline completo!")


# if __name__ == "__main__":
#     app()

from pathlib import Path
import logging
import typer
import pandas as pd
from sklearn.datasets import fetch_openml

from boston_housing import dataset
from boston_housing.config import PROCESSED_DATA_DIR, RAW_DATA_DIR
from boston_housing.modeling import train as train_module

# Inicializa Typer e Logger
app = typer.Typer()
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")


@app.command()
def main(
    raw_filename: Path = RAW_DATA_DIR / "boston_raw.csv",
    processed_filename: Path = PROCESSED_DATA_DIR / "boston.csv",
    model_type: str = typer.Option("random_forest", help="Modelo de regress√£o: random_forest, svr, knn"),
):
    """
    Pipeline Boston Housing:
    1Ô∏è‚É£ Carrega dataset Boston Housing (OpenML) e salva raw/processado
    2Ô∏è‚É£ Separa features e target
    3Ô∏è‚É£ Treina modelo de regress√£o e loga no MLFlow
    """
    # --- 1Ô∏è‚É£ Carregar dataset ---
    logger.info("üì• Carregando Boston Housing dataset...")
    boston = fetch_openml(name="boston", version=1, as_frame=True)
    df = boston.frame  # j√° vem como DataFrame

    # Salvar raw e processed
    dataset.save_raw(df, raw_filename.name)
    processed_path = dataset.save_processed(df, processed_filename.name)
    logger.info(f"‚úÖ Dataset processado salvo em: {processed_path}")

    # --- 2Ô∏è‚É£ Separar features e target ---
    logger.info("üîß Separando features e target...")
    df_processed = pd.read_csv(processed_path)
    if "target" not in df_processed.columns:
        raise ValueError("Coluna 'target' n√£o encontrada no dataset processado.")
    
    features_path = PROCESSED_DATA_DIR / "features.csv"
    labels_path = PROCESSED_DATA_DIR / "labels.csv"

    df_processed.drop(columns=["target"]).to_csv(features_path, index=False)
    df_processed["target"].to_csv(labels_path, index=False)
    logger.info(f"‚úÖ Features salvas em: {features_path}")
    logger.info(f"‚úÖ Labels salvas em: {labels_path}")

    # --- 3Ô∏è‚É£ Treinar modelo ---
    logger.info(f"üèãÔ∏è Treinando modelo de regress√£o: {model_type}")
    train_module.main(
        features_path=features_path,
        labels_path=labels_path,
        overwrite=True,
        experiment_name="boston_housing_experiment",
        model_type=model_type,
    )

    logger.info("‚úÖ Pipeline completo!")


if __name__ == "__main__":
    app()
